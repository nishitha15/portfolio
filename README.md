# Data Engineer

**#About Me**

I'm a Data Engineer with 6 years of experience building and optimizing ETL pipelines, data architectures, and big data solutions across AWS, Azure, and GCP. I have hands-on expertise in Apache Spark (PySpark, Scala), Hadoop, and Kafka, handling large-scale data processing efficiently. I specialize in data modeling, warehousing, and performance tuning using Snowflake, Redshift, and Synapse Analytics. I’ve worked extensively with Apache Airflow, Databricks, and cloud-native data services to streamline workflows and enable real-time analytics. My core skills include SQL, Python, and Scala, with a strong focus on data transformation and automation. I also have experience with CI/CD pipelines, DevOps practices, and containerization (Docker, Kubernetes). I enjoy collaborating with teams to build scalable, cost-effective data solutions and leverage cloud and big data technologies to power business intelligence and analytics.

**Technical Expertise**
•	Programming: Python, SQL, Bash, Shell scripting
•	Frameworks: Databricks, Snowflake, Airflow
•	Database: PostgreSQL, Amazon Redshift, Oracle, MySQL, MongoDB	 
•	API: RESTful API Design, API Gateway, MuleSoft API.
•	Data Integration: AWS Glue, Apache NiFi, Informatica, Azure Data Factory, Cloud Data Fusion	 	•	⁠Cloud Platforms: AWS (S3, Redshift, Glue, Lambda, Athena, EMR, Kinesis), Azure (ADF, Synapse, Data Lake), GCP (BigQuery, Dataflow, Cloud Composer, Pub/Sub)	 
•	⁠Data Modeling: Normalization, Star Schema, Snowflake Schema
•	⁠Tools: Git, Jenkins, Docker, Kubernetes, Jira, 
•	⁠Testing: Unit Testing, Integration Testing, Performance Tuning

# Professional Experience

**Data Engineer II
Lowes, Charlotte
January 2024- Present**
•	Developed and implemented automated testing frameworks using Test-Driven Development (TDD) practices, ensuring high-quality GCP-based data solutions met business requirements.
•	Designed and optimized data architectures on Google Cloud Storage and BigQuery, enabling efficient storage, retrieval, and processing of large-scale datasets for analytics.
•	Built and managed data pipelines using Apache Beam with Dataflow, automating data ingestion, transformation, and processing for real-time and batch workflows.
•	Implemented streaming data ingestion solutions using Pub/Sub and Dataflow, reducing data latency and enabling real-time analytics for faster decision-making.
•	Developed scalable ETL workflows using Cloud Data Fusion and Dataflow, ensuring seamless extraction, transformation, and loading of structured and unstructured data.
•	Developed a metadata-driven ETL framework to dynamically process multiple datasets, reducing manual effort and increasing pipeline scalability.
•	Optimized query performance in BigQuery, leveraging partitioning, clustering, and materialized views, reducing query execution time and cost.
•	Ensured data security and governance compliance by implementing IAM policies, encryption techniques, and VPC Service Controls, protecting sensitive information across GCP environments.
•	Designed and optimized data warehouses in BigQuery, improving storage efficiency and analytical performance for business intelligence and reporting.
•	Automated ETL workflows using Apache Airflow with Cloud Composer, ensuring efficient orchestration of data pipelines and timely data availability.

**Data Engineer II
Fannie Mae, Reston, VA
September 2022- Dec 2023**
•	Optimized complex SQL queries in Amazon Redshift and RDS, improving query execution speed and reducing computational costs through indexing, partitioning, and query tuning.
•	Built and maintained ETL workflows using AWS Glue, enabling seamless data integration, transformation, and automation across AWS services.
•	Developed automated data pipelines leveraging AWS Data Pipeline and AWS Lambda, streamlining data movement and reducing manual intervention.
•	Engineered and optimized data warehouse solutions using Amazon Redshift, enhancing data storage, retrieval, and analytical performance.
•	Created dynamic dashboards in Power BI, visualizing business KPIs and performance metrics to support data-driven decision-making.
•	Optimized data partitioning and indexing strategies in Amazon Redshift, improving query performance and minimizing data retrieval times.
•	Automated data validation processes using AWS Lambda, ensuring data accuracy, compliance, and reducing errors in reporting.
•	Integrated real-time data processing using AWS Kinesis and AWS Lambda, enabling fast, scalable data ingestion and analytics.
•	Built and deployed serverless data applications with AWS Lambda and AWS API Gateway, enhancing data accessibility and system scalability.
•	Monitored and managed data pipelines with AWS CloudWatch, ensuring reliable performance, proactive issue detection, and system health.


	 
