# Data Engineer

**#About Me**

I'm a Data Engineer with 6 years of experience building and optimizing ETL pipelines, data architectures, and big data solutions across AWS, Azure, and GCP. I have hands-on expertise in Apache Spark (PySpark, Scala), Hadoop, and Kafka, handling large-scale data processing efficiently. I specialize in data modeling, warehousing, and performance tuning using Snowflake, Redshift, and Synapse Analytics. Iâ€™ve worked extensively with Apache Airflow, Databricks, and cloud-native data services to streamline workflows and enable real-time analytics. My core skills include SQL, Python, and Scala, with a strong focus on data transformation and automation. I also have experience with CI/CD pipelines, DevOps practices, and containerization (Docker, Kubernetes). I enjoy collaborating with teams to build scalable, cost-effective data solutions and leverage cloud and big data technologies to power business intelligence and analytics.

**Technical Expertise**
